{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eIrvnAbGZ1wP"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "_A4IPZ-WZ9H7"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zfiHTzhkmNwd"
   },
   "source": [
    "# Keras RNN API\n",
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/beta/guide/keras/rnn\">\n",
    "    <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />\n",
    "    View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/r2/guide/keras/rnn.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
    "    Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/r2/guide/keras/rnn.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
    "    View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/r2/guide/keras/rnn.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />\n",
    "    Download notebook</a>\n",
    "  </td>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jfOdaQLhXLDR"
   },
   "source": [
    "Recurrent neural network (RNN) is a class of neural network that is very powerful for solving problem with sequential data input. Unlike the feedforward network, an RNN maintains an internal state which is updated at each time-step. allowing it to explore the temporal feature of the input.\n",
    "\n",
    "In Keras, RNN API is designed with the focus of:\n",
    "\n",
    "- *Easy to use*<br>\n",
    "  Builtin `tf.keras.layer.RNN`/`tf.keras.layers.LSTM`/`tf.keras.layers.GRU` layers allow you to quickly build the model by stacking them with Keras `sequential` model, or in `functional` model style.\n",
    "- *Easy to extend*<br>\n",
    "  You could also define your own `tf.keras.layers.AbstractRNNCell` with custom behavior, and use it with RNN layer. This allows you to quickly prototype different research ideas with minimal amount of code.\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QGJH5EKYoSHZ"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wJEBe8hTlB6W"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "!pip install -q tensorflow-gpu==2.0.0-beta1\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DznzjxWCilt4"
   },
   "source": [
    "## Build a simple model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H5tPG7KJirBj"
   },
   "source": [
    "There are three builtin RNN layers:\n",
    "\n",
    "1. `tf.keras.layers.SimpleRNN`, fully-connected RNN where the output from previous timestep is to be fed to next timestep.\n",
    "\n",
    "1. `tf.keras.layers.GRU`, gated recurrent unit that is first proposed in [https://arxiv.org/abs/1406.1078]\n",
    "\n",
    "1. `tf.keras.layers.LSTM`, Long Short-Term Memory layer that is first proposed in [https://www.bioinf.jku.at/publications/older/2604.pdf].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QHdAFEATnFpn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          64000     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 164,106\n",
      "Trainable params: 164,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "# Add an embedding layer which the expectation of input vocab to be 1000, and\n",
    "# output embedding domain to be 64.\n",
    "model.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
    "\n",
    "# Add an LSTM layer with 128 internal units.\n",
    "model.add(layers.LSTM(128))\n",
    "\n",
    "# Add an Dense layer with 10 units and softmax activation.\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sVT4R7O3qDXM"
   },
   "source": [
    "## Output and states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IOQnPR9eqLwk"
   },
   "source": [
    "By default, the output of the RNN layer is the computation result for the last timestep. The shape of the output is usually `[batch, units]` where the units is the configured during the layer initialization. \n",
    "\n",
    "Instead of just returning the final timestep output, the layer could be configured to return the output for the whole sequence. To enable that, set the `return_sequences` parameter to `True` when creating the layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wNlkR8oXpNEx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 64)          64000     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, None, 64)          24960     \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 128)               24704     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 114,954\n",
      "Trainable params: 114,954\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
    "\n",
    "# The output shape for GRU will be a 3D tensor [batch, sequence, 64]\n",
    "model.add(layers.GRU(64, return_sequences=True))\n",
    "model.add(layers.SimpleRNN(128))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1HagyjYos5rD"
   },
   "source": [
    "In addition, a layer could return the final internal state. The returned states can be used continue the RNN execution later, or to [initialize another RNN](https://arxiv.org/abs/1409.3215). This setting is commonly used in the encoder-decoder model, where the encoder final state is feed to decoder as initial state.\n",
    "\n",
    "To enable that, set the `return_state` parameter to `True` when creating the layer.\n",
    "\n",
    "To config the initial state of the layer, just call the layer with additional keyword argument \"initial_state\". Note that the shape of the state need to match with the unit size of the layer, which is way both LSTM layers are configured to have same size 64 in the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2_HsGBrDvaea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 64)     64000       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 64)     128000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "encoder (LSTM)                  [(None, 64), (None,  33024       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder (LSTM)                  (None, 64)           33024       embedding_3[0][0]                \n",
      "                                                                 encoder[0][1]                    \n",
      "                                                                 encoder[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           650         decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 258,698\n",
      "Trainable params: 258,698\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_vocab = 1000\n",
    "decoder_vocab = 2000\n",
    "\n",
    "encoder_input = layers.Input(shape=(None, ))\n",
    "encoder_embedded = layers.Embedding(input_dim=encoder_vocab, output_dim=64)(encoder_input)\n",
    "\n",
    "output, state_h, state_c = layers.LSTM(\n",
    "    64, return_state=True, name='encoder')(encoder_embedded)\n",
    "encoder_state = [state_h, state_c]\n",
    "\n",
    "decoder_input = layers.Input(shape=(None, ))\n",
    "decoder_embedded = layers.Embedding(input_dim=decoder_vocab, output_dim=64)(decoder_input)\n",
    "\n",
    "decoder_output = layers.LSTM(\n",
    "    64, name='decoder')(decoder_embedded, initial_state=encoder_state)\n",
    "output = layers.Dense(10, activation='softmax')(decoder_output)\n",
    "\n",
    "model = tf.keras.Model([encoder_input, decoder_input], output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EvAaiMJbWR2A"
   },
   "source": [
    "To reuse the RNN state between batchs, you could make the RNN layer to be stateful by set `stateful=True` when construct the layer. It will make RNN layer to keep reusing the final states from the last batch and use it as the initial state for next batch. This allows RNN to explore the feature between batchs, rather than treat individual batch separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E6TsLXJ0X3Xd"
   },
   "outputs": [],
   "source": [
    "paragraph1 = np.random.random((20, 10, 50)).astype(np.float32)\n",
    "paragraph2 = np.random.random((20, 10, 50)).astype(np.float32)\n",
    "paragraph3 = np.random.random((20, 10, 50)).astype(np.float32)\n",
    "\n",
    "# This is same as feeding paragraph1, 2 and 3 that is concat together on axis 1,\n",
    "# which has shape [20, 30, 50]. It allows user to use samller amount of memory. \n",
    "lstm_layer = layers.LSTM(64, stateful=True)\n",
    "output = lstm_layer(paragraph1)\n",
    "output = lstm_layer(paragraph2)\n",
    "output = lstm_layer(paragraph3)\n",
    "\n",
    "# reset_state() will reset the cached state to original initial_state, in the\n",
    "# case that no initial_state is provided, zeros will be used as default.\n",
    "lstm_layer.reset_states()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7AtPur5BDzb4"
   },
   "source": [
    "##Bidirectional RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OsdEIXXREL_N"
   },
   "source": [
    "For sequential inputs, it is often that the model can perform better if it not only process the input from start to end, but also backwards. For example, to predict the next word in the sentence, it is often to have the context around the word, not only just the words in front of it.\n",
    "\n",
    "Keras provides an easy API for you to build bidirectional RNN, by `tf.keras.layers.Bidirectional` wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MNhYIAXqYl3B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional (Bidirectional (None, 5, 128)            38400     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 64)                41216     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 80,266\n",
      "Trainable params: 80,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(layers.Bidirectional(layers.LSTM(64, return_sequences=True), \n",
    "                               input_shape=(5, 10)))\n",
    "model.add(layers.Bidirectional(layers.LSTM(32)))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ThwlodTjZCU0"
   },
   "source": [
    "Under the hood, `Bidirectional` will copy the RNN layer passed in, flip the `go_backwards` field of the newly copied layer, so that it will process the inputs in a reversed order.\n",
    "\n",
    "The output of the `Bidirectional` RNN will be, by default, add the forward layer output with backward layer output. If you want to have different behavior, eg concat the output, or not merge them at all, change the `merge_mode` parameter during `Bidirectional` wrapper initialization. For more details about `Bidirectional`, please check the API doc in https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Bidirectional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ANGN956w6FRs"
   },
   "source": [
    "## Performance upgrade and CuDNN kernel in 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "76xAs7epaX21"
   },
   "source": [
    "In Tensorflow 2.0, the built-in RNN layer has been updated to leverage CuDNN kernel by default when GPU is available. With this change, the existing `keras.layers.CuDNNLSTM/CuDNNGRU` layer can be deprecated, and you can build the model without worrying about the hardware constraint.\n",
    "\n",
    "Since the CuDNN kernel is built with certain assumptions, this means the layer will not be able to use the CuDNN kernel if you configure the build-in layer with some custom behavior. Eg:\n",
    "\n",
    "- Change the `activation` function from `tanh` to something else.\n",
    "- Change the `recurrent_activation` function from `sigmoid` to something else.\n",
    "- Use `recurrent_dropout` > 0\n",
    "- Set `unroll` to True, which force LSTM/GRU to decompose the tf.while loop into a series operations.\n",
    "- Does not use bias.\n",
    "- When using masked input, the input data is not strictly right padded.\n",
    "\n",
    "For the detailed list of contrains, please see the docstring for [LSTM](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/LSTM) and [GRU](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/GRU) layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ybd73JmvqLp4"
   },
   "source": [
    "### Use CuDNN kernel when available\n",
    "\n",
    "Let's build a simple RNN model to train and predict with MNIST dataset to demonstrate the performance difference. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m9kM9hwRsxMx"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "# MNIST input is a (batch, 28, 28, 1) image.\n",
    "# timestep is the first 28 here, and the input_size is the second 28.\n",
    "timestep = 28\n",
    "input_size = 28\n",
    "\n",
    "units = 64\n",
    "output_size = 10  # label is from 0~9\n",
    "\n",
    "# Build the RNN model\n",
    "def build_model(allow_cudnn_kernel=True):\n",
    "  # CuDNN kernel is only available at layer level, and not on cell level.\n",
    "  # This means LSTM(units) will land on CuDNN kernel, while RNN(LSTMCell(units))\n",
    "  # will run on non-CuDNN kernel.\n",
    "  if allow_cudnn_kernel:\n",
    "    lstm_layer = tf.keras.layers.LSTM(units, input_shape=(timestep, input_size))\n",
    "  else:\n",
    "    lstm_layer = tf.keras.layers.RNN(\n",
    "        tf.keras.layers.LSTMCell(units),\n",
    "        input_shape=(timestep, input_size))\n",
    "  model = tf.keras.models.Sequential([\n",
    "      lstm_layer,\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.Dense(output_size, activation='softmax')]\n",
    "  )\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uuztNezFh0BL"
   },
   "source": [
    "### Load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m_kZTLDobchi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "sample, sample_label = x_train[0], y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UXF8elCuib8k"
   },
   "source": [
    "### Create model instance and compile it\n",
    "We choose `sparse_categorical_crossentropy` as the loss function for the model. The output of the model is a logit after `softmax` activation, which has the shape of `[batch, 10]`. The target for the model is a integer vector, each of the integer is in the range of 0 to 9. `sparse_categorical_crossentropy` will properly map the logits output to the integer (index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "klgv6dfK0KNb"
   },
   "outputs": [],
   "source": [
    "model = build_model(allow_cudnn_kernel=True)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qzeeo65r25CU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0712 00:52:48.153316 140616482031360 deprecation.py:323] From /tmpfs/src/tf_docs_env/lib/python3.5/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 0.9204 - accuracy: 0.7047 - val_loss: 0.5371 - val_accuracy: 0.8219\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.3720 - accuracy: 0.8893 - val_loss: 0.2942 - val_accuracy: 0.9100\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.2457 - accuracy: 0.9267 - val_loss: 0.2447 - val_accuracy: 0.9232\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.1963 - accuracy: 0.9410 - val_loss: 0.2004 - val_accuracy: 0.9342\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 0.1697 - accuracy: 0.9489 - val_loss: 0.3147 - val_accuracy: 0.8942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe2d009e160>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=batch_size, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kvCWAssZjsdW"
   },
   "source": [
    "### Build a new model without CuDNN kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H2JfHDOhOFtx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "60000/60000 [==============================] - 34s 574us/sample - loss: 0.1516 - accuracy: 0.9545 - val_loss: 0.1554 - val_accuracy: 0.9493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe2855efef0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_model = build_model(allow_cudnn_kernel=False)\n",
    "slow_model.set_weights(model.get_weights())\n",
    "slow_model.compile(loss='sparse_categorical_crossentropy', \n",
    "                   optimizer='sgd', \n",
    "                   metrics=['accuracy'])\n",
    "slow_model.fit(x_train, y_train, \n",
    "               validation_data=(x_test, y_test), \n",
    "               batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zx8QLf81dTVr"
   },
   "source": [
    "As you can see at this point, the model built with CuDNN kernel is much fast to train, comparing to the model that use normal kernel. With the new implementation of LSTM/GRU layer, user could train their model without the hardware constrains in mind. The same model code can be deployed to any enviornment.\n",
    "\n",
    "The same model can also be use to run single step inference on CPU only environment. The tf.device annotation below is just forcing the device placement. The model will run on CPU by default if GPU is not avaiable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z_z1eRh1fMBL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted result is: [5], target result is: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "with tf.device(\"CPU:0\"):\n",
    "  cpu_model = build_model(allow_cudnn_kernel=True)\n",
    "  cpu_model.set_weights(model.get_weights())\n",
    "  result = tf.argmax(cpu_model.predict_on_batch(tf.expand_dims(sample, 0)), axis=1)\n",
    "  print(\"Predicted result is: %s, target result is: %s\" % (result.numpy(), sample_label))\n",
    "  plt.imshow(sample, cmap=plt.get_cmap(\"gray\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kJDJSXjZ2VaY"
   },
   "source": [
    "## Layer and cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hQRxLRSS2gDf"
   },
   "source": [
    "In addition to built-in RNN layers, the RNN API also provide cell level API for user to use. In contrast to RNN layer, which processes the whole input sequence, the RNN cell focuses on the input for a single timestep.\n",
    "\n",
    "There are three built-in RNN cells, each of them corresponds to the matching RNN layer.\n",
    "\n",
    "- `tf.keras.layers.SimpleRNNCell` matches to SimpleRNN layer.\n",
    "\n",
    "- `tf.keras.layers.GRUCell` matches to GRU layer.\n",
    "\n",
    "- `tf.keras.layers.LSTMCell` matches to LSTM layer.\n",
    "\n",
    "Mathametically `RNN(SimpleRNNCell(10))` should produce the same result as `SimpleRNN(10)`. In fact, the implementation of layer in TF v1.x is just creating the corresponding RNN cell and wrap it with RNN layer.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2mCetBoTiqcB"
   },
   "source": [
    "## RNN with nested structure as input and output\n",
    "\n",
    "Nested structure allow user to encapsulate more information within one single timestep. For example, a video frame could have audio input at the same time. The data shape for this case can be:\n",
    "\n",
    "`[batch, timestep, {\"video\": [height, width, channel], \"audio\": [frequency]}]`\n",
    "\n",
    "In another example, handwriting data could have both x and y for the current frequency of the finger, as well as how hard user is pressing. So the data representation will be:\n",
    "\n",
    "`[batch, timestep, {\"location\": [x, y], \"press\": [force]}]`\n",
    "\n",
    "In any of these cases, it will be nice to have access the overall data for the \n",
    "single timestep, so that the relationship between different data can be explored.\n",
    "\n",
    "The following code gives an example for how to build a custom RNN cell that accept high dimentional input and process it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A1IkIxWykSZQ"
   },
   "source": [
    "### Define a custom cell that support nested input/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6yOT8nSqzp4A"
   },
   "outputs": [],
   "source": [
    "NestedInput = collections.namedtuple('NestedInput', ['feature1', 'feature2'])\n",
    "NestedState = collections.namedtuple('NestedState', ['state1', 'state2'])\n",
    "\n",
    "class NestedCell(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, unit_1, unit_2, unit_3, **kwargs):\n",
    "    self.unit_1 = unit_1\n",
    "    self.unit_2 = unit_2\n",
    "    self.unit_3 = unit_3\n",
    "    self.state_size = NestedState(state1=unit_1, \n",
    "                                  state2=tf.TensorShape([unit_2, unit_3]))\n",
    "    self.output_size = (unit_1, tf.TensorShape([unit_2, unit_3]))\n",
    "    super(NestedCell, self).__init__(**kwargs)\n",
    "\n",
    "  def build(self, inputs_shape):\n",
    "    # expect input_shape to contain 2 items, [(batch, i1), (batch, i2, i3)]\n",
    "    input_1 = inputs_shape.feature1[1]\n",
    "    input_2, input_3 = inputs_shape.feature2[1:]\n",
    "\n",
    "    self.kernel_1 = self.add_weight(\n",
    "        shape=(input_1, self.unit_1), initializer='uniform', name='kernel_1')\n",
    "    self.kernel_2_3 = self.add_weight(\n",
    "        shape=(input_2, input_3, self.unit_2, self.unit_3),\n",
    "        initializer='uniform',\n",
    "        name='kernel_2_3')\n",
    "\n",
    "  def call(self, inputs, states):\n",
    "    # inputs should be in [(batch, input_1), (batch, input_2, input_3)]\n",
    "    # state should be in shape [(batch, unit_1), (batch, unit_2, unit_3)]\n",
    "    input_1, input_2 = tf.nest.flatten(inputs)\n",
    "    s1, s2 = states\n",
    "\n",
    "    output_1 = tf.matmul(input_1, self.kernel_1)\n",
    "    output_2_3 = tf.einsum('bij,ijkl->bkl', input_2, self.kernel_2_3)\n",
    "    state_1 = s1 + output_1\n",
    "    state_2_3 = s2 + output_2_3\n",
    "\n",
    "    output = [output_1, output_2_3]\n",
    "    new_states = NestedState(state1=state_1, state2=state_2_3)\n",
    "\n",
    "    return output, new_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BJHOrrybk6Zy"
   },
   "source": [
    "### Build a RNN model with nested input/output\n",
    "\n",
    "With RNN cell defined, let's build a Keras model that uses the RNN layer and newly defined cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "itrDe0Y2qPjP"
   },
   "outputs": [],
   "source": [
    "unit_1 = 10\n",
    "unit_2 = 20\n",
    "unit_3 = 30\n",
    "\n",
    "input_1 = 32\n",
    "input_2 = 64\n",
    "input_3 = 32\n",
    "batch_size = 64\n",
    "num_batch = 100\n",
    "timestep = 50\n",
    "\n",
    "cell = NestedCell(unit_1, unit_2, unit_3)\n",
    "rnn = tf.keras.layers.RNN(cell)\n",
    "\n",
    "inp_1 = tf.keras.Input((None, input_1))\n",
    "inp_2 = tf.keras.Input((None, input_2, input_3))\n",
    "\n",
    "outputs = rnn(NestedInput(feature1=inp_1, feature2=inp_2))\n",
    "\n",
    "model = tf.keras.models.Model([inp_1, inp_2], outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2MaihTM2mDcp"
   },
   "source": [
    "### Train the model with random generated data\n",
    "Since there isn't a good candidate dataset for this model, numpy random is used here to show case that the model can be trained properly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lN-imRqElz2S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6400 samples\n",
      "6400/6400 [==============================] - 8s 1ms/sample - loss: 0.3702 - rnn_1_loss: 0.1109 - rnn_1_1_loss: 0.2593 - rnn_1_accuracy: 0.0947 - rnn_1_1_accuracy: 0.0331\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe284e71828>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_1_data = np.random.random((batch_size * num_batch, timestep, input_1))\n",
    "input_2_data = np.random.random((batch_size * num_batch, timestep, input_2, input_3))\n",
    "target_1_data = np.random.random((batch_size * num_batch, unit_1))\n",
    "target_2_data = np.random.random((batch_size * num_batch, unit_2, unit_3))\n",
    "input_data = [input_1_data, input_2_data]\n",
    "target_data = [target_1_data, target_2_data]\n",
    "\n",
    "model.fit(input_data, target_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oDdrwgBWnjYp"
   },
   "source": [
    "With the RNN layer API, You are only expected to define the math logic for individual step within the sequence, and Keras RNN layer will handle the sequence iteration for you. For more details, please visit the [API doc](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/RNN)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Keras RNN in 2.0",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "1HPl2jtq6GNqfaJaFSt77kf4bpPr785Fr",
     "timestamp": 1560797934655
    }
   ],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
