{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ISubpr_SSsiM"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "3jTMb1dySr3V"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6DWfyNThSziV"
   },
   "source": [
    "# tf.function\n",
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/beta/tutorials/eager/tf_function\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/r2/tutorials/eager/tf_function.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/r2/tutorials/eager/tf_function.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/r2/tutorials/eager/tf_function.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J122XQYG7W6w"
   },
   "source": [
    "\n",
    "In TensorFlow 2.0, eager execution is turned on by default. The user interface is intuitive and flexible (running one-off operations is much easier\n",
    "and faster), but this can come at the expense of performance and deployability.\n",
    "\n",
    "To get peak performance and to make your model deployable anywhere, use\n",
    "`tf.function` to make graphs out of your programs.\n",
    "Thanks to AutoGraph, a surprising amount of Python code just works with\n",
    "tf.function, but there are still pitfalls to be wary of.\n",
    "\n",
    "The main takeaways and recommendations are:\n",
    "\n",
    "- Don't rely on Python side effects like object mutation or list appends.\n",
    "- tf.function works best with TensorFlow ops, rather than NumPy ops or Python primitives.\n",
    "- When in doubt, use the `for x in y` idiom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "otIdN1TS8N7S"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "!pip install -q tensorflow==2.0.0-beta1\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D25apou9IOXa"
   },
   "outputs": [],
   "source": [
    "import contextlib\n",
    "\n",
    "# Some helper code to demonstrate the kinds of errors you might encounter.\n",
    "@contextlib.contextmanager\n",
    "def assert_raises(error_class):\n",
    "  try:\n",
    "    yield\n",
    "  except error_class as e:\n",
    "    print('Caught expected exception \\n  {}: {}'.format(error_class, e))\n",
    "  except Exception as e:\n",
    "    print('Got unexpected exception \\n  {}: {}'.format(type(e), e))\n",
    "  else:\n",
    "    raise Exception('Expected {} to be raised but no error was raised!'.format(\n",
    "        error_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rfayNj-ZIkIB"
   },
   "source": [
    "A `tf.function` you define is just like a core TensorFlow operation: You can execute it eagerly; you can use it in a graph; it has gradients; and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SbtT1-Wm70F2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=14, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 2.],\n",
       "       [2., 2.]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A function is like an op\n",
    "\n",
    "@tf.function\n",
    "def add(a, b):\n",
    "  return a + b\n",
    "\n",
    "add(tf.ones([2, 2]), tf.ones([2, 2]))  #  [[2., 2.], [2., 2.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uP-zUelB8DbX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=40, shape=(), dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Functions have gradients\n",
    "\n",
    "@tf.function\n",
    "def add(a, b):\n",
    "  return a + b\n",
    "\n",
    "v = tf.Variable(1.0)\n",
    "with tf.GradientTape() as tape:\n",
    "  result = add(v, 1.0)\n",
    "tape.gradient(result, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l5qRjdbBVdU6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=67, shape=(3, 2), dtype=float32, numpy=\n",
       "array([[3., 3.],\n",
       "       [3., 3.],\n",
       "       [3., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can use functions inside functions\n",
    "\n",
    "@tf.function\n",
    "def dense_layer(x, w, b):\n",
    "  return add(tf.matmul(x, w), b)\n",
    "\n",
    "dense_layer(tf.ones([3, 2]), tf.ones([2, 2]), tf.ones([2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uZ4Do2AV80cO"
   },
   "source": [
    "## Tracing and polymorphism\n",
    "\n",
    "Python's dynamic typing means that you can call functions with a variety of argument types, and Python will do something different in each scenario.\n",
    "\n",
    "On the other hand, TensorFlow graphs require static dtypes and shape dimensions. `tf.function` bridges this gap by retracing the function when necessary to generate the correct graphs. Most of the subtlety of `tf.function` usage stems from this retracing behavior.\n",
    "\n",
    "You can call a function with arguments of different types to see what is happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kojmJrgq8U9v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing with Tensor(\"a:0\", shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "\n",
      "Tracing with Tensor(\"a:0\", shape=(), dtype=float32)\n",
      "tf.Tensor(2.2, shape=(), dtype=float32)\n",
      "\n",
      "Tracing with Tensor(\"a:0\", shape=(), dtype=string)\n",
      "tf.Tensor(b'aa', shape=(), dtype=string)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Functions are polymorphic\n",
    "\n",
    "@tf.function\n",
    "def double(a):\n",
    "  print(\"Tracing with\", a)\n",
    "  return a + a\n",
    "\n",
    "print(double(tf.constant(1)))\n",
    "print()\n",
    "print(double(tf.constant(1.1)))\n",
    "print()\n",
    "print(double(tf.constant(\"a\")))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4pJqkDR_Q2wz"
   },
   "source": [
    "To control the tracing behavior, use the following techniques:\n",
    "\n",
    "- Create a new `tf.function`. Separate `tf.function` objects are guaranteed not to share traces. \n",
    "- Use the `get_concrete_function` method to get a specific trace\n",
    "- Specify `input_signature` when calling `tf.function` to trace only once per calling graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mHg2CGtPQ3Hz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining concrete trace\n",
      "Tracing with Tensor(\"a:0\", dtype=string)\n",
      "Executing traced function\n",
      "tf.Tensor(b'aa', shape=(), dtype=string)\n",
      "tf.Tensor(b'bb', shape=(), dtype=string)\n",
      "Using a concrete trace with incompatible types will throw an error\n",
      "Caught expected exception \n",
      "  <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>: cannot compute __inference_double_98 as input #0(zero-based) was expected to be a string tensor but is a int32 tensor [Op:__inference_double_98]\n"
     ]
    }
   ],
   "source": [
    "print(\"Obtaining concrete trace\")\n",
    "double_strings = double.get_concrete_function(tf.TensorSpec(shape=None, dtype=tf.string))\n",
    "print(\"Executing traced function\")\n",
    "print(double_strings(tf.constant(\"a\")))\n",
    "print(double_strings(a=tf.constant(\"b\")))\n",
    "print(\"Using a concrete trace with incompatible types will throw an error\")\n",
    "with assert_raises(tf.errors.InvalidArgumentError):\n",
    "  double_strings(tf.constant(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_BDMIRmu1RGB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing with Tensor(\"x:0\", shape=(None,), dtype=int32)\n",
      "tf.Tensor([4 1], shape=(2,), dtype=int32)\n",
      "Caught expected exception \n",
      "  <class 'ValueError'>: Python inputs incompatible with input_signature: inputs ((<tf.Tensor: id=125, shape=(2, 2), dtype=int32, numpy=\n",
      "array([[1, 2],\n",
      "       [3, 4]], dtype=int32)>,)), input_signature ((TensorSpec(shape=(None,), dtype=tf.int32, name=None),))\n"
     ]
    }
   ],
   "source": [
    "@tf.function(input_signature=(tf.TensorSpec(shape=[None], dtype=tf.int32),))\n",
    "def next_collatz(x):\n",
    "  print(\"Tracing with\", x)\n",
    "  return tf.where(tf.equal(x % 2, 0), x // 2, 3 * x + 1)\n",
    "\n",
    "print(next_collatz(tf.constant([1, 2])))\n",
    "# We specified a 1-D tensor in the input signature, so this should fail.\n",
    "with assert_raises(ValueError):\n",
    "  next_collatz(tf.constant([[1, 2], [3, 4]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Es0WZkLIUSdu"
   },
   "source": [
    "## When to retrace?\n",
    "\n",
    "A polymorphic `tf.function` keeps a cache of concrete functions generated by tracing. The cache keys are effectively tuples of keys generated from the function args and kwargs. The key generated for a `tf.Tensor` argument is its shape and type. The key generated for a Python primitive is its value. For all other Python types, the keys are based on the object `id()` so that methods are traced independently for each instance of a class. In the future, TensorFlow may add more sophisticated caching for Python objects that can be safely converted to tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AY5oiQN0XIyA"
   },
   "source": [
    "## Python or Tensor args?\n",
    "\n",
    "Often, Python arguments are used to control hyperparameters and graph constructions - for example, `num_layers=10` or `training=True` or `nonlinearity='relu'`. So if the Python argument changes, it makes sense that you'd have to retrace the graph.\n",
    "\n",
    "However, it's possible that a Python argument is not being used to control graph construction. In these cases, a change in the Python value can trigger needless retracing. Take, for example, this training loop, which AutoGraph will dynamically unroll. Despite the multiple traces, the generated graph is actually identical, so this is a bit inefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uydzR5JYUU8H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing with num_steps = 10\n",
      "Tracing with num_steps = 20\n"
     ]
    }
   ],
   "source": [
    "def train_one_step():\n",
    "  pass\n",
    "\n",
    "@tf.function\n",
    "def train(num_steps):\n",
    "  print(\"Tracing with num_steps = {}\".format(num_steps))\n",
    "  for _ in tf.range(num_steps):\n",
    "    train_one_step()\n",
    "\n",
    "train(num_steps=10)\n",
    "train(num_steps=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f6pjnylLUW8P"
   },
   "source": [
    "The simple workaround here is to cast your arguments to Tensors if they do not affect the shape of the generated graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TmL8T-w3UYes"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing with num_steps = Tensor(\"num_steps:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "train(num_steps=tf.constant(10))\n",
    "train(num_steps=tf.constant(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "129-iRsPS-gY"
   },
   "source": [
    "## Side effects in `tf.function`\n",
    "\n",
    "In general, Python side effects (like printing or mutating objects) only happen during tracing. So how can you reliably trigger side effects from `tf.function`?\n",
    "\n",
    "The general rule of thumb is to only use Python side effects to debug your traces. Otherwise, TensorFlow ops like `tf.Variable.assign`, `tf.print`, and `tf.summary` are the best way to ensure your code will be traced and executed by the TensorFlow runtime with each call. In general using a functional style will yield the best results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w2sACuZ9TTRk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traced with 1\n",
      "Executed with 1\n",
      "Executed with 1\n",
      "Traced with 2\n",
      "Executed with 2\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def f(x):\n",
    "  print(\"Traced with\", x)\n",
    "  tf.print(\"Executed with\", x)\n",
    "\n",
    "f(1)\n",
    "f(1)\n",
    "f(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e1I0dPiqTV8H"
   },
   "source": [
    "If you would like to execute Python code during each invocation of a `tf.function`, `tf.py_function` is an exit hatch. The drawback of `tf.py_function` is that it's not portable or particularly performant, nor does it work well in distributed (multi-GPU, TPU) setups. Also, since `tf.py_function` has to be wired into the graph, it casts all inputs/outputs to tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7aJD--9qTWmg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0629 01:08:56.691862 140487172290304 backprop.py:842] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.int32\n",
      "W0629 01:08:56.694054 140487155504896 backprop.py:842] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.int32\n",
      "W0629 01:08:56.695917 140487172290304 backprop.py:842] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.int32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python side effect\n",
      "Python side effect\n",
      "Python side effect\n"
     ]
    }
   ],
   "source": [
    "external_list = []\n",
    "\n",
    "def side_effect(x):\n",
    "  print('Python side effect')\n",
    "  external_list.append(x)\n",
    "\n",
    "@tf.function\n",
    "def f(x):\n",
    "  tf.py_function(side_effect, inp=[x], Tout=[])\n",
    "\n",
    "f(1)\n",
    "f(1)\n",
    "f(1)\n",
    "assert len(external_list) == 3\n",
    "# .numpy() call required because py_function casts 1 to tf.constant(1)\n",
    "assert external_list[0].numpy() == 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "msTmv-oyUNaf"
   },
   "source": [
    "## Beware of Python state\n",
    "\n",
    "Many Python features, such as generators and iterators, rely on the Python runtime to keep track of state. In general, while these constructs work as expected in Eager mode, many unexpected things can happen inside a `tf.function` due to tracing behavior.\n",
    "\n",
    "To give one example, advancing iterator state is a Python side effect and therefore only happens during tracing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FNPD4unZUedH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of external_var: 0\n",
      "Value of external_var: 0\n",
      "Value of external_var: 0\n"
     ]
    }
   ],
   "source": [
    "external_var = tf.Variable(0)\n",
    "@tf.function\n",
    "def buggy_consume_next(iterator):\n",
    "  external_var.assign_add(next(iterator))\n",
    "  tf.print(\"Value of external_var:\", external_var)\n",
    "\n",
    "iterator = iter([0, 1, 2, 3])\n",
    "buggy_consume_next(iterator)\n",
    "# This reuses the first value from the iterator, rather than consuming the next value.\n",
    "buggy_consume_next(iterator)\n",
    "buggy_consume_next(iterator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5XMGXMu-Ufjm"
   },
   "source": [
    "If an iterator is generated and consumed entirely within the tf.function, then it should work correctly. However, the entire iterator is probably being traced, which can lead to a giant graph. This may be what you want. But if you're training on an large in-memory dataset represented as a Python list, then this can generate a very large graph, and `tf.function` is unlikely to yield a speedup.\n",
    "\n",
    "If you want to iterate over Python data, the safest way is to wrap it in a tf.data.Dataset and use the `for x in y` idiom. AutoGraph has special support for safely converting `for` loops when `y` is a tensor or tf.data.Dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ms7f1o_QUiHE"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0629 01:08:57.038732 140490414335744 deprecation.py:323] From /tmpfs/src/tf_docs_env/lib/python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py:505: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train([(1, 1), (1, 1)]) contains 8 nodes in its graph\n",
      "train([(1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1)]) contains 32 nodes in its graph\n",
      "train(<DatasetV1Adapter shapes: (<unknown>, <unknown>), types: (tf.int32, tf.int32)>) contains 4 nodes in its graph\n",
      "train(<DatasetV1Adapter shapes: (<unknown>, <unknown>), types: (tf.int32, tf.int32)>) contains 4 nodes in its graph\n"
     ]
    }
   ],
   "source": [
    "def measure_graph_size(f, *args):\n",
    "  g = f.get_concrete_function(*args).graph\n",
    "  print(\"{}({}) contains {} nodes in its graph\".format(\n",
    "      f.__name__, ', '.join(map(str, args)), len(g.as_graph_def().node)))\n",
    "\n",
    "@tf.function\n",
    "def train(dataset):\n",
    "  loss = tf.constant(0)\n",
    "  for x, y in dataset:\n",
    "    loss += tf.abs(y - x) # Some dummy computation.\n",
    "  return loss\n",
    "\n",
    "small_data = [(1, 1)] * 2\n",
    "big_data = [(1, 1)] * 10\n",
    "measure_graph_size(train, small_data)\n",
    "measure_graph_size(train, big_data)\n",
    "\n",
    "measure_graph_size(train, tf.data.Dataset.from_generator(\n",
    "    lambda: small_data, (tf.int32, tf.int32)))\n",
    "measure_graph_size(train, tf.data.Dataset.from_generator(\n",
    "    lambda: big_data, (tf.int32, tf.int32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dGDstsFpWHEI"
   },
   "source": [
    "\n",
    "When wrapping Python/Numpy data in a Dataset, be mindful of `tf.data.Dataset.from_generator` versus ` tf.data.Dataset.from_tensors`. The former will keep the data in Python and fetch it via `tf.py_function` which can have performance implications, whereas the latter will bundle a copy of the data as one large `tf.constant()` node in the graph, which can have memory implications.\n",
    "\n",
    "Reading data from files via TFRecordDataset/CsvDataset/etc. is the most effective way to consume data, as then TensorFlow itself can manage the asynchronous loading and prefetching of data, without having to involve Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tRdlnCfV_UTn"
   },
   "source": [
    "## Automatic Control Dependencies\n",
    "\n",
    "A very appealing property of functions as the programming model, over a general dataflow graph, is that functions can give the runtime more information about what was the intended behavior of the code.\n",
    "\n",
    "For example, when writing code which has multiple reads and writes to the same variables, a dataflow graph might not naturally encode the originally intended order of operations. In `tf.function`, we resolve ambiguities in execution order by referring to the execution order of statements in the original Python code. This way, ordering of stateful operations in a `tf.function` replicates the semantics of Eager mode.\n",
    "\n",
    "This means there's no need to add manual control dependencies; `tf.function` is smart enough to add the minimal set of necessary and sufficient control dependencies for your code to run correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SASm0ss8erVX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=460, shape=(), dtype=float32, numpy=10.0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Automatic control dependencies\n",
    "\n",
    "a = tf.Variable(1.0)\n",
    "b = tf.Variable(2.0)\n",
    "\n",
    "@tf.function\n",
    "def f(x, y):\n",
    "  a.assign(y * b)\n",
    "  b.assign_add(x * a)\n",
    "  return a + b\n",
    "\n",
    "f(1.0, 2.0)  # 10.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lPr_6mK_AQWL"
   },
   "source": [
    "## Variables\n",
    "\n",
    "We can use the same idea of leveraging the intended execution order of the code to make variable creation and utilization very easy in `tf.function`. There is one very important caveat, though, which is that with variables it's possible to write code which behaves differently in eager mode and graph mode.\n",
    "\n",
    "Specifically, this will happen when you create a new Variable with each call. Due to tracing semantics, `tf.function` will reuse the same variable each call, but eager mode will create a new variable with each call. To guard against this mistake, `tf.function` will raise an error if it detects dangerous variable creation behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tx0Vvnb_9OB-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught expected exception \n",
      "  <class 'ValueError'>: in converted code:\n",
      "\n",
      "    <ipython-input-17-73e410646579>:3 f  *\n",
      "        v = tf.Variable(1.0)\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.5/site-packages/tensorflow/python/ops/variables.py:262 __call__\n",
      "        return cls._variable_v2_call(*args, **kwargs)\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.5/site-packages/tensorflow/python/ops/variables.py:256 _variable_v2_call\n",
      "        shape=shape)\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.5/site-packages/tensorflow/python/ops/variables.py:60 getter\n",
      "        return captured_getter(captured_previous, **kwargs)\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.5/site-packages/tensorflow/python/eager/def_function.py:364 invalid_creator_scope\n",
      "        \"tf.function-decorated function tried to create \"\n",
      "\n",
      "    ValueError: tf.function-decorated function tried to create variables on non-first call.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def f(x):\n",
    "  v = tf.Variable(1.0)\n",
    "  v.assign_add(x)\n",
    "  return v\n",
    "\n",
    "with assert_raises(ValueError):\n",
    "  f(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DKzNjVg8h4ao"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.0, shape=(), dtype=float32)\n",
      "tf.Tensor(4.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Non-ambiguous code is ok though\n",
    "\n",
    "v = tf.Variable(1.0)\n",
    "\n",
    "@tf.function\n",
    "def f(x):\n",
    "  return v.assign_add(x)\n",
    "\n",
    "print(f(1.0))  # 2.0\n",
    "print(f(2.0))  # 4.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HQrG5_kOiKl_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.0, shape=(), dtype=float32)\n",
      "tf.Tensor(4.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# You can also create variables inside a tf.function as long as we can prove\n",
    "# that those variables are created only the first time the function is executed.\n",
    "\n",
    "class C: pass\n",
    "obj = C(); obj.v = None\n",
    "\n",
    "@tf.function\n",
    "def g(x):\n",
    "  if obj.v is None:\n",
    "    obj.v = tf.Variable(1.0)\n",
    "  return obj.v.assign_add(x)\n",
    "\n",
    "print(g(1.0))  # 2.0\n",
    "print(g(2.0))  # 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_IOVc1eujMH2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(12.0, shape=(), dtype=float32)\n",
      "tf.Tensor(36.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Variable initializers can depend on function arguments and on values of other\n",
    "# variables. We can figure out the right initialization order using the same\n",
    "# method we use to generate control dependencies.\n",
    "\n",
    "state = []\n",
    "@tf.function\n",
    "def fn(x):\n",
    "  if not state:\n",
    "    state.append(tf.Variable(2.0 * x))\n",
    "    state.append(tf.Variable(state[0] * 3.0))\n",
    "  return state[0] * x * state[1]\n",
    "\n",
    "print(fn(tf.constant(1.0)))\n",
    "print(fn(tf.constant(3.0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5f05Vr_YBUCz"
   },
   "source": [
    "# Using AutoGraph\n",
    "\n",
    "The [autograph](https://www.tensorflow.org/guide/autograph) library is fully integrated with `tf.function`, and it will rewrite conditionals and loops which depend on Tensors to run dynamically in the graph.\n",
    "\n",
    "`tf.cond` and `tf.while_loop` continue to work with `tf.function`, but code with control flow is often easier to write and understand when written in imperative style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yCQTtTPTW3WF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.604465961 0.235631824 0.292372584 0.0933123827 0.8393749]\n",
      "[0.540219843 0.231365576 0.284317046 0.093042478 0.685477853]\n",
      "[0.493154347 0.227323771 0.276895881 0.0927749 0.595069051]\n",
      "[0.456716418 0.223487303 0.270029694 0.0925096273 0.533531547]\n",
      "[0.427404225 0.219839349 0.263652474 0.0922466218 0.488075942]\n",
      "[0.403149694 0.21636492 0.257708609 0.0919858441 0.452688]\n",
      "[0.382640719 0.213050663 0.252151072 0.0917272717 0.424106032]\n",
      "[0.364998549 0.209884614 0.2469396 0.0914708674 0.40038386]\n",
      "[0.349609256 0.206856042 0.242039666 0.091216594 0.380277365]\n",
      "[0.336028934 0.203955248 0.237421349 0.0909644365 0.362948328]\n",
      "[0.323927581 0.201173469 0.233058617 0.0907143652 0.347808361]\n",
      "[0.313053906 0.198502809 0.228928685 0.0904663429 0.334430456]\n",
      "[0.303212792 0.195936009 0.225011513 0.0902203396 0.322496086]\n",
      "[0.294249982 0.193466514 0.221289411 0.0899763331 0.311762124]\n",
      "[0.286041766 0.191088319 0.21774666 0.0897343 0.302039325]\n",
      "[0.278487593 0.188795939 0.214369327 0.0894942135 0.293177754]\n",
      "[0.27150473 0.186584324 0.21114485 0.0892560408 0.285056978]\n",
      "[0.265024424 0.184448823 0.208062038 0.0890197605 0.27757892]\n",
      "[0.258989 0.182385176 0.205110788 0.0887853503 0.270662814]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=727, shape=(5,), dtype=float32, numpy=\n",
       "array([0.25334966, 0.1803894 , 0.202282  , 0.08855279, 0.26424146],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple loop\n",
    "\n",
    "@tf.function\n",
    "def f(x):\n",
    "  while tf.reduce_sum(x) > 1:\n",
    "    tf.print(x)\n",
    "    x = tf.tanh(x)\n",
    "  return x\n",
    "\n",
    "f(tf.random.uniform([5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jlQD1ffRXJhl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__f(x):\n",
      "  do_return = False\n",
      "  retval_ = ag__.UndefinedReturnValue()\n",
      "\n",
      "  def loop_test(x_1):\n",
      "    return ag__.converted_call('reduce_sum', tf, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (x_1,), None) > 1\n",
      "\n",
      "  def loop_body(x_1):\n",
      "    ag__.converted_call('print', tf, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (x_1,), None)\n",
      "    x_1 = ag__.converted_call('tanh', tf, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (x_1,), None)\n",
      "    return x_1,\n",
      "  x, = ag__.while_stmt(loop_test, loop_body, (x,))\n",
      "  do_return = True\n",
      "  retval_ = x\n",
      "  cond = ag__.is_undefined_return(retval_)\n",
      "\n",
      "  def get_state():\n",
      "    return ()\n",
      "\n",
      "  def set_state(_):\n",
      "    pass\n",
      "\n",
      "  def if_true():\n",
      "    retval_ = None\n",
      "    return retval_\n",
      "\n",
      "  def if_false():\n",
      "    return retval_\n",
      "  retval_ = ag__.if_stmt(cond, if_true, if_false, get_state, set_state)\n",
      "  return retval_\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# If you're curious you can inspect the code autograph generates.\n",
    "# It feels like reading assembly language, though.\n",
    "\n",
    "def f(x):\n",
    "  while tf.reduce_sum(x) > 1:\n",
    "    tf.print(x)\n",
    "    x = tf.tanh(x)\n",
    "  return x\n",
    "\n",
    "print(tf.autograph.to_code(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xgKmkrNTZSyz"
   },
   "source": [
    "## AutoGraph: Conditionals\n",
    "\n",
    "AutoGraph will convert `if` statements into the equivalent `tf.cond` calls.\n",
    "\n",
    "This substitution is made if the condition is a Tensor. Otherwise, the conditional is executed during tracing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E-7KllizZYsy"
   },
   "outputs": [],
   "source": [
    "def test_tf_cond(f, *args):\n",
    "  g = f.get_concrete_function(*args).graph\n",
    "  if any(node.name == 'cond' for node in g.as_graph_def().node):\n",
    "    print(\"{}({}) uses tf.cond.\".format(\n",
    "        f.__name__, ', '.join(map(str, args))))\n",
    "  else:\n",
    "    print(\"{}({}) executes normally.\".format(\n",
    "        f.__name__, ', '.join(map(str, args))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o86paGR-Zadi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyperparam_cond(tf.Tensor([1.], shape=(1,), dtype=float32)) executes normally.\n",
      "maybe_tensor_cond(tf.Tensor(-1, shape=(), dtype=int32)) uses tf.cond.\n",
      "maybe_tensor_cond(-1) executes normally.\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def hyperparam_cond(x, training=True):\n",
    "  if training:\n",
    "    x = tf.nn.dropout(x, rate=0.5)\n",
    "  return x\n",
    "\n",
    "@tf.function\n",
    "def maybe_tensor_cond(x):\n",
    "  if x < 0:\n",
    "    x = -x\n",
    "  return x\n",
    "\n",
    "test_tf_cond(hyperparam_cond, tf.ones([1], dtype=tf.float32))\n",
    "test_tf_cond(maybe_tensor_cond, tf.constant(-1))\n",
    "test_tf_cond(maybe_tensor_cond, -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5xFLfdApZh8q"
   },
   "source": [
    "`tf.cond` has a number of subtleties.\n",
    "- it works by tracing both sides of the conditional, and then choosing the appropriate branch at runtime, depending on the condition. Tracing both sides can result in unexpected execution of Python code\n",
    "- it requires that if one branch creates a tensor used downstream, the other branch must also create that tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VTMoZEVaZiwk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing `then` branch\n",
      "Tracing `else` branch\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=802, shape=(), dtype=int32, numpy=1>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def f():\n",
    "  x = tf.constant(0)\n",
    "  if tf.constant(True):\n",
    "    x = x + 1\n",
    "    print(\"Tracing `then` branch\")\n",
    "  else:\n",
    "    x = x - 1\n",
    "    print(\"Tracing `else` branch\")\n",
    "  return x\n",
    "\n",
    "f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k_dxWHeFZlaQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught expected exception \n",
      "  <class 'ValueError'>: in converted code:\n",
      "\n",
      "    <ipython-input-26-3ae6a92ff50d>:3 f  *\n",
      "        if tf.constant(True):\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.5/site-packages/tensorflow/python/autograph/operators/control_flow.py:439 if_stmt\n",
      "        return tf_if_stmt(cond, body, orelse, get_state, set_state)\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.5/site-packages/tensorflow/python/autograph/operators/control_flow.py:456 tf_if_stmt\n",
      "        outputs, final_state = control_flow_ops.cond(cond, body, orelse)\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py:507 new_func\n",
      "        return func(*args, **kwargs)\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py:1147 cond\n",
      "        return cond_v2.cond_v2(pred, true_fn, false_fn, name)\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.5/site-packages/tensorflow/python/ops/cond_v2.py:86 cond_v2\n",
      "        op_return_value=pred)\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.5/site-packages/tensorflow/python/framework/func_graph.py:716 func_graph_from_py_func\n",
      "        func_outputs = python_func(*func_args, **func_kwargs)\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.5/site-packages/tensorflow/python/autograph/operators/control_flow.py:486 wrapper\n",
      "        outputs = func()\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.5/site-packages/tensorflow/python/autograph/operators/control_flow.py:512 wrapper\n",
      "        tuple(s.symbol_name for s in undefined)))\n",
      "\n",
      "    ValueError: The following symbols must also be initialized in the else branch: ('x',). Alternatively, you may initialize them before the if statement.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def f():\n",
    "  if tf.constant(True):\n",
    "    x = tf.ones([3, 3])\n",
    "  return x\n",
    "\n",
    "# Throws an error because both branches need to define `x`.\n",
    "with assert_raises(ValueError):\n",
    "  f()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yho4J0a0ZkQS"
   },
   "source": [
    "## AutoGraph and loops\n",
    "\n",
    "AutoGraph has a few simple rules for converting loops.\n",
    "\n",
    "- `for`: Convert if the iterable is a tensor\n",
    "- `while`: Convert if the while condition depends on a tensor\n",
    "\n",
    "If a loop is converted, it will be dynamically unrolled with `tf.while_loop`, or in the special case of a `for x in tf.data.Dataset`, transformed into `tf.data.Dataset.reduce`.\n",
    "\n",
    "If a loop is _not_ converted, it will be statically unrolled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OyzGNQAuZsky"
   },
   "outputs": [],
   "source": [
    "def test_dynamically_unrolled(f, *args):\n",
    "  g = f.get_concrete_function(*args).graph\n",
    "  if any(node.name == 'while' for node in g.as_graph_def().node):\n",
    "    print(\"{}({}) uses tf.while_loop.\".format(\n",
    "        f.__name__, ', '.join(map(str, args))))\n",
    "  elif any(node.name == 'ReduceDataset' for node in g.as_graph_def().node):\n",
    "    print(\"{}({}) uses tf.data.Dataset.reduce.\".format(\n",
    "        f.__name__, ', '.join(map(str, args))))\n",
    "  else:\n",
    "    print(\"{}({}) gets unrolled.\".format(\n",
    "        f.__name__, ', '.join(map(str, args))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q7tmncQTZt6_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for_in_range() gets unrolled.\n",
      "for_in_tfrange() uses tf.while_loop.\n",
      "for_in_tfdataset() uses tf.data.Dataset.reduce.\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def for_in_range():\n",
    "  x = 0\n",
    "  for i in range(5):\n",
    "    x += i\n",
    "  return x\n",
    "\n",
    "@tf.function\n",
    "def for_in_tfrange():\n",
    "  x = tf.constant(0, dtype=tf.int32)\n",
    "  for i in tf.range(5):\n",
    "    x += i\n",
    "  return x\n",
    "\n",
    "@tf.function\n",
    "def for_in_tfdataset():\n",
    "  x = tf.constant(0, dtype=tf.int64)\n",
    "  for i in tf.data.Dataset.range(5):\n",
    "    x += i\n",
    "  return x\n",
    "\n",
    "test_dynamically_unrolled(for_in_range)\n",
    "test_dynamically_unrolled(for_in_tfrange)\n",
    "test_dynamically_unrolled(for_in_tfdataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l6s7aU-padY5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "while_py_cond() gets unrolled.\n",
      "while_tf_cond() uses tf.while_loop.\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def while_py_cond():\n",
    "  x = 5\n",
    "  while x > 0:\n",
    "    x -= 1\n",
    "  return x\n",
    "\n",
    "@tf.function\n",
    "def while_tf_cond():\n",
    "  x = tf.constant(5)\n",
    "  while x > 0:\n",
    "    x -= 1\n",
    "  return x\n",
    "\n",
    "test_dynamically_unrolled(while_py_cond)\n",
    "test_dynamically_unrolled(while_tf_cond)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dSr64Xn6ap-S"
   },
   "source": [
    " If you have a `break` or early `return` clause that depends on a tensor, the top-level condition or iterable should also be a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q-VirD-5avdZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught expected exception \n",
      "  <class 'TypeError'>: in converted code:\n",
      "\n",
      "    <ipython-input-30-220fba6e1df8>:3 buggy_while_py_true_tf_break  *\n",
      "        while True:\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.5/site-packages/tensorflow/python/autograph/operators/control_flow.py:313 while_stmt\n",
      "        return _py_while_stmt(test, body, init_state, opts)\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.5/site-packages/tensorflow/python/autograph/operators/control_flow.py:401 _py_while_stmt\n",
      "        while test(*state):\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py:698 __bool__\n",
      "        raise TypeError(\"Using a `tf.Tensor` as a Python `bool` is not allowed. \"\n",
      "\n",
      "    TypeError: Using a `tf.Tensor` as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined, and use TensorFlow ops such as tf.cond to execute subgraphs conditioned on the value of a tensor.\n",
      "\n",
      "while_tf_true_tf_break(5) uses tf.while_loop.\n",
      "Caught expected exception \n",
      "  <class 'TypeError'>: in converted code:\n",
      "\n",
      "    <ipython-input-30-220fba6e1df8>:24 buggy_py_for_tf_break  *\n",
      "        for i in range(5):\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.5/site-packages/tensorflow/python/autograph/operators/control_flow.py:110 for_stmt\n",
      "        return _py_for_stmt(iter_, extra_test, body, init_state)\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.5/site-packages/tensorflow/python/autograph/operators/control_flow.py:117 _py_for_stmt\n",
      "        if extra_test is not None and not extra_test(*state):\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py:698 __bool__\n",
      "        raise TypeError(\"Using a `tf.Tensor` as a Python `bool` is not allowed. \"\n",
      "\n",
      "    TypeError: Using a `tf.Tensor` as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined, and use TensorFlow ops such as tf.cond to execute subgraphs conditioned on the value of a tensor.\n",
      "\n",
      "tf_for_tf_break() uses tf.while_loop.\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def buggy_while_py_true_tf_break(x):\n",
    "  while True:\n",
    "    if tf.equal(x, 0):\n",
    "      break\n",
    "    x -= 1\n",
    "  return x\n",
    "\n",
    "@tf.function\n",
    "def while_tf_true_tf_break(x):\n",
    "  while tf.constant(True):\n",
    "    if tf.equal(x, 0):\n",
    "      break\n",
    "    x -= 1\n",
    "  return x\n",
    "\n",
    "with assert_raises(TypeError):\n",
    "  test_dynamically_unrolled(buggy_while_py_true_tf_break, 5)\n",
    "test_dynamically_unrolled(while_tf_true_tf_break, 5)\n",
    "\n",
    "@tf.function\n",
    "def buggy_py_for_tf_break():\n",
    "  x = 0\n",
    "  for i in range(5):\n",
    "    if tf.equal(i, 3):\n",
    "      break\n",
    "    x += i\n",
    "  return x\n",
    "\n",
    "@tf.function\n",
    "def tf_for_tf_break():\n",
    "  x = 0\n",
    "  for i in tf.range(5):\n",
    "    if tf.equal(i, 3):\n",
    "      break\n",
    "    x += i\n",
    "  return x\n",
    "\n",
    "with assert_raises(TypeError):\n",
    "  test_dynamically_unrolled(buggy_py_for_tf_break)\n",
    "test_dynamically_unrolled(tf_for_tf_break)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hyksHW9TCukR"
   },
   "source": [
    "In order to accumulate results from a dynamically unrolled loop, you'll want to use `tf.TensorArray`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HJ3Vb3dXfefN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1307, shape=(2, 3, 4), dtype=float32, numpy=\n",
       "array([[[0.2641269 , 0.32148373, 0.27760386, 0.871022  ],\n",
       "        [0.36447   , 0.82768893, 1.1970165 , 1.2398282 ],\n",
       "        [1.1957974 , 1.242557  , 1.2163385 , 1.7522211 ]],\n",
       "\n",
       "       [[0.11496973, 0.8242916 , 0.5828695 , 0.01092482],\n",
       "        [0.64337647, 1.7383248 , 1.182523  , 0.94805145],\n",
       "        [1.2105927 , 1.9715753 , 1.2999045 , 1.6146696 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "seq_len = 3\n",
    "feature_size = 4\n",
    "\n",
    "def rnn_step(inp, state):\n",
    "  return inp + state\n",
    "\n",
    "@tf.function\n",
    "def dynamic_rnn(rnn_step, input_data, initial_state):\n",
    "  # [batch, time, features] -> [time, batch, features]\n",
    "  input_data = tf.transpose(input_data, [1, 0, 2])\n",
    "  max_seq_len = input_data.shape[0]\n",
    "\n",
    "  states = tf.TensorArray(tf.float32, size=max_seq_len)\n",
    "  state = initial_state\n",
    "  for i in tf.range(max_seq_len):\n",
    "    state = rnn_step(input_data[i], state)\n",
    "    states = states.write(i, state)\n",
    "  return tf.transpose(states.stack(), [1, 0, 2])\n",
    "  \n",
    "dynamic_rnn(rnn_step,\n",
    "            tf.random.uniform([batch_size, seq_len, feature_size]),\n",
    "            tf.zeros([batch_size, feature_size]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9gmLpHY-bkly"
   },
   "source": [
    "As with `tf.cond`, `tf.while_loop` also comes with a number of subtleties.\n",
    "- Since a loop can execute 0 times, all tensors used downstream of the while_loop must be initialized above the loop\n",
    "- The shape/dtypes of all loop variables must stay consistent with each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CocT5RHwblrQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught expected exception \n",
      "  <class 'ValueError'>: in converted code:\n",
      "\n",
      "    <ipython-input-32-4012abce963a>:3 buggy_loop_var_uninitialized  *\n",
      "        for i in tf.range(3):\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.5/site-packages/tensorflow/python/autograph/operators/control_flow.py:95 for_stmt\n",
      "        return _known_len_tf_for_stmt(iter_, extra_test, body, init_state)\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.5/site-packages/tensorflow/python/autograph/operators/control_flow.py:125 _known_len_tf_for_stmt\n",
      "        _disallow_undefs_into_loop(*init_state)\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.5/site-packages/tensorflow/python/autograph/operators/control_flow.py:50 _disallow_undefs_into_loop\n",
      "        tuple(s.symbol_name for s in undefined)))\n",
      "\n",
      "    ValueError: TensorFlow requires that the following symbols must be defined before the loop: ('x',)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1371, shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def buggy_loop_var_uninitialized():\n",
    "  for i in tf.range(3):\n",
    "    x = i\n",
    "  return x\n",
    "\n",
    "@tf.function\n",
    "def f():\n",
    "  x = tf.constant(0)\n",
    "  for i in tf.range(3):\n",
    "    x = i\n",
    "  return x\n",
    "\n",
    "with assert_raises(ValueError):\n",
    "  buggy_loop_var_uninitialized()\n",
    "f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FSftc9cCbpAo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught expected exception \n",
      "  <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>: Input 1 of node while/merge/_10 was passed int32 from while/next_iteration/_28:0 incompatible with expected float. [Op:__inference_buggy_loop_type_changes_1428]\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def buggy_loop_type_changes():\n",
    "  x = tf.constant(0, dtype=tf.float32)\n",
    "  for i in tf.range(3): # Yields tensors of type tf.int32...\n",
    "    x = i\n",
    "  return x\n",
    "\n",
    "with assert_raises(tf.errors.InvalidArgumentError):\n",
    "  buggy_loop_type_changes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kWF189prbuK0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught expected exception \n",
      "  <class 'ValueError'>: in converted code:\n",
      "\n",
      "    <ipython-input-34-d212bdeeeb5e>:4 buggy_concat  *\n",
      "        for i in tf.range(5):\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.5/site-packages/tensorflow/python/autograph/operators/control_flow.py:95 for_stmt\n",
      "        return _known_len_tf_for_stmt(iter_, extra_test, body, init_state)\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.5/site-packages/tensorflow/python/autograph/operators/control_flow.py:156 _known_len_tf_for_stmt\n",
      "        opts=dict(maximum_iterations=n))\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.5/site-packages/tensorflow/python/autograph/operators/control_flow.py:327 _tf_while_stmt\n",
      "        retval = control_flow_ops.while_loop(test, body, init_state, **opts)\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py:2646 while_loop\n",
      "        return_same_structure=return_same_structure)\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.5/site-packages/tensorflow/python/ops/while_v2.py:213 while_loop\n",
      "        len_orig_loop_vars], expand_composites=True))\n",
      "    /tmpfs/src/tf_docs_env/lib/python3.5/site-packages/tensorflow/python/ops/while_v2.py:869 _check_shapes_compat\n",
      "        \"specify a less-specific shape.\" % (input_t.name, shape, t.shape))\n",
      "\n",
      "    ValueError: Input tensor 'ones:0' enters the loop with shape (0, 10), but has shape (1, 10) after one iteration. To allow the shape to vary across iterations, use the `shape_invariants` argument of tf.while_loop to specify a less-specific shape.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1549, shape=(5, 10), dtype=float32, numpy=\n",
       "array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def buggy_concat():\n",
    "  x = tf.ones([0, 10])\n",
    "  for i in tf.range(5):\n",
    "    x = tf.concat([x, tf.ones([1, 10])], axis=0)\n",
    "  return x\n",
    "\n",
    "with assert_raises(ValueError):\n",
    "  buggy_concat()\n",
    "  \n",
    "@tf.function\n",
    "def concat_with_padding():\n",
    "  x = tf.zeros([5, 10])\n",
    "  for i in tf.range(5):\n",
    "    x = tf.concat([x[:i], tf.ones([1, 10]), tf.zeros([4-i, 10])], axis=0)\n",
    "    x.set_shape([5, 10])\n",
    "  return x\n",
    "\n",
    "concat_with_padding()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ISubpr_SSsiM"
   ],
   "name": "tf.function",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
